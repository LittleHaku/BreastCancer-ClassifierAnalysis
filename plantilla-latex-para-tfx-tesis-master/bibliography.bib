
@misc{njoroge_jean-njorogebreast-cancer-risk-prediction_2024,
	title = {Jean-njoroge/{Breast}-cancer-risk-prediction},
	copyright = {MIT},
	url = {https://github.com/Jean-njoroge/Breast-cancer-risk-prediction},
	abstract = {Classification of Breast Cancer diagnosis Using Support Vector Machines},
	urldate = {2024-01-15},
	author = {Njoroge, Jean-leah},
	month = jan,
	year = {2024},
	note = {original-date: 2016-12-13T04:27:23Z},
	keywords = {breast-cancer-prediction, exploratory-data-analysis, linear-regression, logistic-regression, support-vector-machine, decision-tree, gaussian-naive-bayes, hyperparameter-tuning, knn-classifier, data-preprocessing},
}

@misc{agarap_afagarapwisconsin-breast-cancer_2023,
	title = {{AFAgarap}/wisconsin-breast-cancer},
	copyright = {Apache-2.0},
	url = {https://github.com/AFAgarap/wisconsin-breast-cancer},
	abstract = {[ICMLSC 2018] On Breast Cancer Detection: An Application of Machine Learning Algorithms on the Wisconsin Diagnostic Dataset},
	urldate = {2024-01-15},
	author = {Agarap, Abien Fred},
	month = dec,
	year = {2023},
	note = {original-date: 2017-09-11T15:38:48Z},
	keywords = {breast-cancer-prediction, linear-regression, logistic-regression, machine-learning, multilayer-perceptron, softmax-regression, support-vector-machine, knn-classifier},
}

@misc{bahadur_akshaybahadur21breastcancer_classification_2024,
	title = {akshaybahadur21/{BreastCancer}\_Classification},
	copyright = {MIT},
	url = {https://github.com/akshaybahadur21/BreastCancer_Classification},
	abstract = {Machine learning classifier for cancer tissues üî¨},
	urldate = {2024-01-15},
	author = {Bahadur, Akshay},
	month = jan,
	year = {2024},
	note = {original-date: 2017-10-23T17:00:22Z},
	keywords = {breast-cancer-prediction, logistic-regression, machine-learning},
}

@misc{debbarma_shibajyotidebbarmamachine-learning--scikit-learn-breast-cancer-winconsin-dataset_2023,
	title = {shibajyotidebbarma/{Machine}-{Learning}-with-{Scikit}-{Learn}-{Breast}-{Cancer}-{Winconsin}-{Dataset}},
	url = {https://github.com/shibajyotidebbarma/Machine-Learning-with-Scikit-Learn-Breast-Cancer-Winconsin-Dataset},
	abstract = {In this machine learning project I will work on the Wisconsin Breast Cancer Dataset that comes with scikit-learn. I will train a few algorithms and evaluate their performance. I will use ipython (Jupyter).},
	urldate = {2024-01-15},
	author = {Debbarma, Shibajyoti},
	month = nov,
	year = {2023},
	note = {original-date: 2018-06-23T19:53:32Z},
	keywords = {breast-cancer-prediction, logistic-regression, knn-classifier},
}

@misc{pajo_bora-pajobreast-cancer-prediction_2023,
	title = {bora-pajo/breast-cancer-prediction},
	url = {https://github.com/bora-pajo/breast-cancer-prediction},
	abstract = {Predicting the probability that a diagnosed breast cancer case is malignant or benign based on Wisconsin dataset},
	urldate = {2024-01-15},
	author = {Pajo, Bora},
	month = dec,
	year = {2023},
	note = {original-date: 2017-03-08T21:07:46Z},
	keywords = {logistic-regression, multilayer-perceptron, support-vector-machine, decision-tree, ada-boost, random-forest, quadratic-discriminant-analysis, knn-classifier, naive-bayes-classifier},
}

@article{umer_breast_2022,
	title = {Breast {Cancer} {Detection} {Using} {Convoluted} {Features} and {Ensemble} {Machine} {Learning} {Algorithm}},
	volume = {14},
	issn = {2072-6694},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9737339/},
	doi = {10.3390/cancers14236015},
	abstract = {Simple Summary
This paper presents a breast cancer detection approach where the convoluted features from a convolutional neural network are utilized to train a machine learning model. Results demonstrate that use of convoluted features yields better results than the original features to classify malignant and benign tumors.

Abstract
Breast cancer is a common cause of female mortality in developing countries. Screening and early diagnosis can play an important role in the prevention and treatment of these cancers. This study proposes an ensemble learning-based voting classifier that combines the logistic regression and stochastic gradient descent classifier with deep convoluted features for the accurate detection of cancerous patients. Deep convoluted features are extracted from the microscopic features and fed to the ensemble voting classifier. This idea provides an optimized framework that accurately classifies malignant and benign tumors with improved accuracy. Results obtained using the voting classifier with convoluted features demonstrate that the highest classification accuracy of 100\% is achieved. The proposed approach revealed the accuracy enhancement in comparison with the state-of-the-art approaches.},
	number = {23},
	urldate = {2024-01-16},
	journal = {Cancers},
	author = {Umer, Muhammad and Naveed, Mahum and Alrowais, Fadwa and Ishaq, Abid and Hejaili, Abdullah Al and Alsubai, Shtwai and Eshmawi, Ala‚Äô Abdulmajid and Mohamed, Abdullah and Ashraf, Imran},
	month = dec,
	year = {2022},
	pmid = {36497497},
	pmcid = {PMC9737339},
	keywords = {breast-cancer-prediction, convoluted-features, ensemble-learning, voting-ensemble},
	pages = {6015},
	file = {PubMed Central Full Text PDF:/home/ivan/Zotero/storage/2EEP9XFK/Umer et al. - 2022 - Breast Cancer Detection Using Convoluted Features .pdf:application/pdf},
}

@misc{karanam_exploratory_2022,
	title = {Exploratory {Data} {Analysis} ‚Äî {Breast} {Cancer} {Wisconsin} ({Diagnostic}) {Dataset}},
	url = {https://medium.com/@shashmikaranam/exploratory-data-analysis-breast-cancer-wisconsin-diagnostic-dataset-6a3be9525cd},
	abstract = {Breast Cancer Wisconsin (Diagnostic) Dataset:},
	language = {en},
	urldate = {2024-01-16},
	journal = {Medium},
	author = {Karanam, Shashmi},
	month = sep,
	year = {2022},
	keywords = {exploratory-data-analysis, very-useful},
	file = {Snapshot:/home/ivan/Zotero/storage/6FURYGU3/exploratory-data-analysis-breast-cancer-wisconsin-diagnostic-dataset-6a3be9525cd.html:text/html},
}

@misc{carraro_detanico_breast_2019,
	title = {Breast {Cancer} {Diagnosis} - {EDA} and {Machine} {Learning}},
	url = {https://bdetanico.github.io/Breast-Cancer-Diagnosis/Breast-Cancer-Diagnostic_v5.html},
	abstract = {Exploratory Data Analysis, Preprocessing doing PCA and comparison of KNN, CART (Decision Tree), Random Forest, Logistic Regression and SVM},
	urldate = {2024-01-16},
	author = {Carraro Detanico, Bernardo},
	month = aug,
	year = {2019},
	keywords = {exploratory-data-analysis, logistic-regression, support-vector-machine, decision-tree, random-forest, knn-classifier, principal-component-analysis, data-preprocessing},
}

@article{omotehinwa_light_2023,
	title = {A {Light} {Gradient}-{Boosting} {Machine} algorithm with {Tree}-{Structured} {Parzen} {Estimator} for breast cancer diagnosis},
	volume = {4},
	issn = {2772-4425},
	url = {https://www.sciencedirect.com/science/article/pii/S2772442523000850},
	doi = {10.1016/j.health.2023.100218},
	abstract = {Breast cancer is a common and potentially life-threatening disease. Early and accurate diagnosis of breast cancer is crucial for effective treatment and improved patient outcomes. This study proposed using the Light Gradient-Boosting Machine (LightGBM) algorithm, Borderline- Synthetic Minority Oversampling Technique (SMOTE), and the Tree-Structured Parzen Estimator (TPE) for hyperparameter tuning to enhance the effectiveness of the Machine Learning (ML) model for diagnosing breast cancer. A 10-fold cross-validated TPE optimized Borderline-SMOTE LightGBM classifier was modelled on the Wisconsin Diagnostic Breast Cancer (WDBC) Dataset and evaluated for its performance compared to a baseline LightGBM model. The TPE-optimized Borderline-SMOTE LightGBM model exhibited a significant improvement in performance over the baseline model, achieving an average accuracy of 99.12\%, specificity of 100\%, precision of 100\%, recall of 97.62\%, F1-score of 98.80\%, and a Mathews Correlation Coefficient of 98.12\%. Compared to previous studies, the TPE-optimized Borderline-SMOTE LightGBM model performed exceptionally well. The study demonstrates the effectiveness of using data augmentation and hyperparameter optimization techniques to improve the performance of ML models for breast cancer diagnosis, which has significant implications for the medical field where the accurate and efficient diagnosis of breast cancer is critical.},
	urldate = {2024-01-16},
	journal = {Healthcare Analytics},
	author = {Omotehinwa, Temidayo Oluwatosin and Oyewola, David Opeoluwa and Dada, Emmanuel Gbenga},
	month = dec,
	year = {2023},
	keywords = {breast-cancer-prediction, machine-learning, ensemble-learning, gradient-boosting, hyperparameter-tuning, light-gradient-boosting-machine, tree-structured-parzen-estimator},
	pages = {100218},
	file = {ScienceDirect Snapshot:/home/ivan/Zotero/storage/QPVCJSQU/S2772442523000850.html:text/html},
}

@misc{nighania_various_2019,
	title = {Various ways to evaluate a machine learning models performance},
	url = {https://towardsdatascience.com/various-ways-to-evaluate-a-machine-learning-models-performance-230449055f15},
	abstract = {Because finding accuracy is not enough.},
	language = {en},
	urldate = {2024-01-16},
	journal = {Medium},
	author = {Nighania, Kartik},
	month = jan,
	year = {2019},
	keywords = {machine-learning-evaluation},
	file = {Snapshot:/home/ivan/Zotero/storage/NPPBTKYY/various-ways-to-evaluate-a-machine-learning-models-performance-230449055f15.html:text/html},
}

@misc{choudhury_what_2020,
	title = {What is {Gradient} {Boosting}? {How} is it different from {Ada} {Boost}?},
	shorttitle = {What is {Gradient} {Boosting}?},
	url = {https://medium.com/analytics-vidhya/what-is-gradient-boosting-how-is-it-different-from-ada-boost-2d5ff5767cb2},
	abstract = {Boosting algorithms are one of the most popular and used algorithms. They can be considered as one of the most powerful techniques for‚Ä¶},
	language = {en},
	urldate = {2024-01-16},
	journal = {Analytics Vidhya},
	author = {Choudhury, Abhiroop},
	month = dec,
	year = {2020},
	keywords = {ada-boost, ensemble-learning, gradient-boosting},
	file = {Snapshot:/home/ivan/Zotero/storage/4WZCR947/what-is-gradient-boosting-how-is-it-different-from-ada-boost-2d5ff5767cb2.html:text/html},
}

@misc{scikit_learn_1_nodate,
	title = {1. {Supervised} learning},
	url = {https://scikit-learn/stable/supervised_learning.html},
	abstract = {Linear Models- Ordinary Least Squares, Ridge regression and classification, Lasso, Multi-task Lasso, Elastic-Net, Multi-task Elastic-Net, Least Angle Regression, LARS Lasso, Orthogonal Matching Pur...},
	language = {en},
	urldate = {2024-01-16},
	journal = {scikit-learn},
	author = {{Scikit Learn}},
	file = {Snapshot:/home/ivan/Zotero/storage/2X2QGMLT/supervised_learning.html:text/html},
}

@inproceedings{sharif_moghadam_breast_2019,
	title = {Breast {Cancer} {Classification} {Using} {AdaBoost}- {Extreme} {Learning} {Machine}},
	doi = {10.1109/ICSPIS48872.2019.9066088},
	author = {Sharif Moghadam, Mahboobe and Jazayeriy, Hamid},
	month = dec,
	year = {2019},
	keywords = {breast-cancer-prediction, ada-boost},
	pages = {1--5},
	file = {Full Text PDF:/home/ivan/Zotero/storage/G3IFDQR2/Sharif Moghadam and Jazayeriy - 2019 - Breast Cancer Classification Using AdaBoost- Extre.pdf:application/pdf},
}

@article{minnoor_diagnosis_2023,
	series = {International {Conference} on {Machine} {Learning} and {Data} {Engineering}},
	title = {Diagnosis of {Breast} {Cancer} {Using} {Random} {Forests}},
	volume = {218},
	issn = {1877-0509},
	url = {https://www.sciencedirect.com/science/article/pii/S187705092300025X},
	doi = {10.1016/j.procs.2023.01.025},
	abstract = {Breast cancer was the most diagnosed form of cancer in 2020. Early diagnosis of breast cancer results in a significant improvement in long-term survival rates. Current methods require consultation with experts, which is expensive and time-consuming and thus may not be accessible to all. This paper seeks to train and evaluate supervised machine learning models for the accurate and efficient detection of breast cancer. The Wisconsin Breast Cancer Database dataset describes 30 attributes of cell nuclei, including, but not limited to, their radius, texture, and concavity. It contains 569 instances, 212 of which are malignant tumors. The Random Forest algorithm outperforms other algorithms in classifying breast tumors as either malignant or benign and is thus selected as our primary model. It is trained on two different subsets of the dataset having 16 and 8 features, respectively, identified with the help of multiple feature selection methods. The Random Forest models are tested post hyperparameter tuning on a holdout set, and accuracies of 100\% and 99.30\% respectively. The models are also compared with four other machine learning classification algorithms: Support Vector Machine (SVM), Decision Tree, Multilayer Perceptron, and K-Nearest Neighbors. The results confirm that Random Forest is the superior method for breast cancer diagnosis.},
	urldate = {2024-01-16},
	journal = {Procedia Computer Science},
	author = {Minnoor, Manas and Baths, Veeky},
	month = jan,
	year = {2023},
	keywords = {breast-cancer-prediction, random-forest, hyperparameter-tuning},
	pages = {429--437},
	file = {ScienceDirect Snapshot:/home/ivan/Zotero/storage/AIJLAGHL/S187705092300025X.html:text/html},
}

@article{khatun_cancer_2023,
	title = {Cancer {Classification} {Utilizing} {Voting} {Classifier} with {Ensemble} {Feature} {Selection} {Method} and {Transcriptomic} {Data}},
	volume = {14},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2073-4425},
	url = {https://www.mdpi.com/2073-4425/14/9/1802},
	doi = {10.3390/genes14091802},
	abstract = {Biomarker-based cancer identification and classification tools are widely used in bioinformatics and machine learning fields. However, the high dimensionality of microarray gene expression data poses a challenge for identifying important genes in cancer diagnosis. Many feature selection algorithms optimize cancer diagnosis by selecting optimal features. This article proposes an ensemble rank-based feature selection method (EFSM) and an ensemble weighted average voting classifier (VT) to overcome this challenge. The EFSM uses a ranking method that aggregates features from individual selection methods to efficiently discover the most relevant and useful features. The VT combines support vector machine, k-nearest neighbor, and decision tree algorithms to create an ensemble model. The proposed method was tested on three benchmark datasets and compared to existing built-in ensemble models. The results show that our model achieved higher accuracy, with 100\% for leukaemia, 94.74\% for colon cancer, and 94.34\% for the 11-tumor dataset. This study concludes by identifying a subset of the most important cancer-causing genes and demonstrating their significance compared to the original data. The proposed approach surpasses existing strategies in accuracy and stability, significantly impacting the development of ML-based gene analysis. It detects vital genes with higher precision and stability than other existing methods.},
	language = {en},
	number = {9},
	urldate = {2024-01-16},
	journal = {Genes},
	author = {Khatun, Rabea and Akter, Maksuda and Islam, Md Manowarul and Uddin, Md Ashraf and Talukder, Md Alamin and Kamruzzaman, Joarder and Azad, A. K. M. and Paul, Bikash Kumar and Almoyad, Muhammad Ali Abdulllah and Aryal, Sunil and Moni, Mohammad Ali},
	month = sep,
	year = {2023},
	note = {Number: 9
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {breast-cancer-prediction, machine-learning, ensemble-learning, voting-ensemble, feature-selection},
	pages = {1802},
	file = {Full Text PDF:/home/ivan/Zotero/storage/757L6J7T/Khatun et al. - 2023 - Cancer Classification Utilizing Voting Classifier .pdf:application/pdf},
}

@misc{njoroge_breast-cancer-risk-predictionnb2_exploratorydataanalysisipynb_nodate,
	title = {Breast-cancer-risk-prediction/{NB2}\_ExploratoryDataAnalysis.ipynb at master ¬∑ {Jean}-njoroge/{Breast}-cancer-risk-prediction},
	url = {https://github.com/Jean-njoroge/Breast-cancer-risk-prediction/blob/master/NB2_ExploratoryDataAnalysis.ipynb},
	abstract = {Classification of Breast Cancer diagnosis Using Support Vector Machines - Jean-njoroge/Breast-cancer-risk-prediction},
	language = {en},
	urldate = {2024-01-16},
	journal = {GitHub},
	author = {Njoroge, Jean-leah},
	keywords = {exploratory-data-analysis},
	file = {Snapshot:/home/ivan/Zotero/storage/THEKV93F/NB2_ExploratoryDataAnalysis.html:text/html},
}

@misc{wcrf_international_breast_nodate,
	title = {Breast cancer statistics {\textbar} {World} {Cancer} {Research} {Fund} {International}},
	url = {https://www.wcrf.org/cancer-trends/breast-cancer-statistics/},
	abstract = {Latest statistics on breast cancer, with data on which countries have the highest rates, plus advice on preventing breast cancer.},
	language = {en-US},
	urldate = {2024-01-16},
	journal = {WCRF International},
	author = {{WCRF International}},
	keywords = {breast-cancer-statistics, motivation},
	file = {Snapshot:/home/ivan/Zotero/storage/DIZTPLS9/breast-cancer-statistics.html:text/html},
}

@misc{american_cancer_society_breast_nodate,
	title = {Breast {Cancer} {Statistics} {\textbar} {How} {Common} {Is} {Breast} {Cancer}?},
	url = {https://www.cancer.org/cancer/types/breast-cancer/about/how-common-is-breast-cancer.html},
	abstract = {Read the American Cancer Society‚Äôs latest information and statistics for breast cancer in women in the United States.},
	language = {en},
	urldate = {2024-01-16},
	author = {{American Cancer Society}},
	keywords = {breast-cancer-statistics, motivation},
	file = {Snapshot:/home/ivan/Zotero/storage/P9WCXHYZ/how-common-is-breast-cancer.html:text/html},
}

@article{yu_diagnostic_2012,
	title = {Diagnostic value of fine-needle aspiration biopsy for breast mass: a systematic review and meta-analysis},
	volume = {12},
	issn = {1471-2407},
	shorttitle = {Diagnostic value of fine-needle aspiration biopsy for breast mass},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3283452/},
	doi = {10.1186/1471-2407-12-41},
	abstract = {Background
Fine-needle aspiration biopsy (FNAB) of the breast is a minimally invasive yet maximally diagnostic method. However, the clinical use of FNAB has been questioned. The purpose of our study was to establish the overall value of FNAC in the diagnosis of breast lesions.

Methods
After a review and quality assessment of 46 studies, sensitivity, specificity and other measures of accuracy of FNAB for evaluating breast lesions were pooled using random-effects models. Summary receiver operating characteristic curves were used to summarize overall accuracy. The sensitivity and specificity for the studies data (included unsatisfactory samples) and underestimation rate of unsatisfactory samples were also calculated.

Results
The summary estimates for FNAB in diagnosis of breast carcinoma were as follows (unsatisfactory samples was temporarily exluded): sensitivity, 0.927 (95\% confidence interval [CI], 0.921 to 0.933); specificity, 0.948 (95\% CI, 0.943 to 0.952); positive likelihood ratio, 25.72 (95\% CI, 17.35 to 28.13); negative likelihood ratio, 0.08 (95\% CI, 0.06 to 0.11); diagnostic odds ratio, 429.73 (95\% CI, 241.75 to 763.87); The pooled sensitivity and specificity for 11 studies, which reported unsatisfactory samples (unsatisfactory samples was considered to be positive in this classification) were 0.920 (95\% CI, 0.906 to 0.933) and 0.768 (95\% CI, 0.751 to 0.784) respectively. The pooled proportion of unsatisfactory samples that were subsequently upgraded to various grade cancers was 27.5\% (95\% CI, 0.221 to 0.296).

Conclusions
FNAB is an accurate biopsy for evaluating breast malignancy if rigorous criteria are used. With regard to unsatisfactory samples, futher invasive procedures are required in order to minimize the chance of a missed diagnosis of breast cancer.},
	urldate = {2024-01-16},
	journal = {BMC Cancer},
	author = {Yu, Ying-Hua and Wei, Wei and Liu, Jian-Lun},
	month = jan,
	year = {2012},
	pmid = {22277164},
	pmcid = {PMC3283452},
	keywords = {breast-cancer-statistics, FNAB-statistics, motivation},
	pages = {41},
	file = {PubMed Central Full Text PDF:/home/ivan/Zotero/storage/MSRA3ISW/Yu et al. - 2012 - Diagnostic value of fine-needle aspiration biopsy .pdf:application/pdf},
}

@misc{hall_gecko17kmachinelearningworkflow_2020,
	title = {gecko17k/{MachineLearningWorkflow}},
	url = {https://github.com/gecko17k/MachineLearningWorkflow},
	abstract = {Using breast cancer data to demonstrate a good Machine Learning workflow: loading data, cleaning it, standardising it, comparing different ML models, improving the best, presenting the results.},
	urldate = {2024-01-16},
	author = {Hall, Vincent},
	month = nov,
	year = {2020},
	note = {original-date: 2019-07-22T08:30:32Z},
	keywords = {breast-cancer-prediction, exploratory-data-analysis, logistic-regression, multilayer-perceptron, support-vector-machine, decision-tree, gaussian-naive-bayes, quadratic-discriminant-analysis, knn-classifier, data-preprocessing, linear-discriminant-analysis, very-useful},
}

@misc{baeldung_how_2021,
	title = {How {Many} {Principal} {Components} to {Take} in {PCA}? {\textbar} {Baeldung} on {Computer} {Science}},
	shorttitle = {How {Many} {Principal} {Components} to {Take} in {PCA}?},
	url = {https://www.baeldung.com/cs/pca},
	abstract = {Explore the Principal Component Analysis.},
	language = {en-US},
	urldate = {2024-01-18},
	author = {{baeldung}},
	month = oct,
	year = {2021},
	keywords = {principal-component-analysis},
	file = {Snapshot:/home/ivan/Zotero/storage/JHDNQ5SE/pca.html:text/html},
}

@misc{zhao_pre-process_2019,
	title = {Pre-{Process} {Data} with {Pipeline} to {Prevent} {Data} {Leakage} during {Cross}-{Validation}.},
	url = {https://towardsdatascience.com/pre-process-data-with-pipeline-to-prevent-data-leakage-during-cross-validation-e3442cca7fdc},
	abstract = {In machine learning, K-fold Cross-validation is a frequently used validation technique for assessing how the results of a statistical‚Ä¶},
	language = {en},
	urldate = {2024-01-18},
	journal = {Medium},
	author = {Zhao, Kai},
	month = sep,
	year = {2019},
	keywords = {hyperparameter-tuning, data-preprocessing, cross-validation},
	file = {Snapshot:/home/ivan/Zotero/storage/6TQ6V7TN/pre-process-data-with-pipeline-to-prevent-data-leakage-during-cross-validation-e3442cca7fdc.html:text/html},
}

@misc{pramoditha_how_2023,
	title = {How to {Select} the {Best} {Number} of {Principal} {Components} for the {Dataset}},
	url = {https://towardsdatascience.com/how-to-select-the-best-number-of-principal-components-for-the-dataset-287e64b14c6d},
	abstract = {Six methods you should follow},
	language = {en},
	urldate = {2024-01-18},
	journal = {Medium},
	author = {Pramoditha, Rukshan},
	month = aug,
	year = {2023},
	keywords = {principal-component-analysis},
	file = {Snapshot:/home/ivan/Zotero/storage/23CJTRMQ/how-to-select-the-best-number-of-principal-components-for-the-dataset-287e64b14c6d.html:text/html},
}

@misc{scikit_learn_31_nodate,
	title = {3.1. {Cross}-validation: evaluating estimator performance},
	shorttitle = {3.1. {Cross}-validation},
	url = {https://scikit-learn/stable/modules/cross_validation.html},
	abstract = {Learning the parameters of a prediction function and testing it on the same data is a methodological mistake: a model that would just repeat the labels of the samples that it has just seen would ha...},
	language = {en},
	urldate = {2024-01-19},
	journal = {scikit-learn},
	author = {{Scikit Learn}},
	keywords = {cross-validation},
	file = {Snapshot:/home/ivan/Zotero/storage/AJURQ6WZ/cross_validation.html:text/html},
}

@misc{mwiti_comprehensive_2022,
	title = {A {Comprehensive} {Guide} to {Ensemble} {Learning}: {What} {Exactly} {Do} {You} {Need} to {Know}},
	shorttitle = {A {Comprehensive} {Guide} to {Ensemble} {Learning}},
	url = {https://neptune.ai/blog/ensemble-learning-guide},
	abstract = {Explore ensemble learning methods, libraries for stacking, and optimal use-cases in a straightforward guide.},
	language = {en-US},
	urldate = {2024-01-19},
	journal = {neptune.ai},
	author = {Mwiti, Derrick},
	month = jul,
	year = {2022},
	keywords = {ensemble-learning},
	file = {Snapshot:/home/ivan/Zotero/storage/9V2ABLR2/ensemble-learning-guide.html:text/html},
}

@misc{srivastava_powerful_2015,
	title = {Powerful '{Trick}' to choose right models in {Ensemble} {Learning}},
	url = {https://www.analyticsvidhya.com/blog/2015/10/trick-right-model-ensemble/},
	abstract = {Ensemble modeling boost the power of predictive model. This trick to select the right model helps to build accurate machine learning models},
	language = {en},
	urldate = {2024-01-19},
	journal = {Analytics Vidhya},
	author = {Srivastava, Tavish},
	month = oct,
	year = {2015},
	keywords = {ensemble-learning, very-useful},
	file = {Snapshot:/home/ivan/Zotero/storage/Y24EMGEH/trick-right-model-ensemble.html:text/html},
}

@misc{nantasenamat_codepythoncomparing-classifiersipynb_nodate,
	title = {code/python/comparing-classifiers.ipynb at master ¬∑ dataprofessor/code},
	url = {https://github.com/dataprofessor/code/blob/master/python/comparing-classifiers.ipynb},
	abstract = {Compilation of R and Python programming codes on the Data Professor YouTube channel. - dataprofessor/code},
	language = {en},
	urldate = {2024-01-19},
	journal = {GitHub},
	author = {Nantasenamat, Chanin},
	keywords = {compare-classifiers},
	file = {Snapshot:/home/ivan/Zotero/storage/T5YND5BW/comparing-classifiers.html:text/html},
}

@misc{pandian_comprehensive_2022,
	title = {A {Comprehensive} {Guide} on {Hyperparameter} {Tuning} and its {Techniques}},
	url = {https://www.analyticsvidhya.com/blog/2022/02/a-comprehensive-guide-on-hyperparameter-tuning-and-its-techniques/},
	abstract = {Every Data Scientist must understand the significance of hyperparameter tuning techniques while selecting right Machine Learning model.},
	language = {en},
	urldate = {2024-01-19},
	journal = {Analytics Vidhya},
	author = {Pandian, Shanthababu},
	month = feb,
	year = {2022},
	keywords = {hyperparameter-tuning},
	file = {Snapshot:/home/ivan/Zotero/storage/9JAZ7NKS/a-comprehensive-guide-on-hyperparameter-tuning-and-its-techniques.html:text/html},
}

@misc{firebug_answer_2016,
	title = {Answer to "{Practical} hyperparameter optimization: {Random} vs. grid search"},
	shorttitle = {Answer to "{Practical} hyperparameter optimization},
	url = {https://stats.stackexchange.com/a/209409},
	urldate = {2024-01-20},
	journal = {Cross Validated},
	author = {Firebug},
	month = apr,
	year = {2016},
	keywords = {hyperparameter-tuning, random-search-cv},
	file = {Snapshot:/home/ivan/Zotero/storage/YYZB8285/practical-hyperparameter-optimization-random-vs-grid-search.html:text/html},
}

@misc{ismiguzel_hyperparameter_2023,
	title = {Hyperparameter {Tuning} with {Grid} {Search} and {Random} {Search}},
	url = {https://towardsdatascience.com/hyperparameter-tuning-with-grid-search-and-random-search-6e1b5e175144},
	abstract = {And a deep dive into how to combine them},
	language = {en},
	urldate = {2024-01-20},
	journal = {Medium},
	author = {Ismiguzel, Idil},
	month = mar,
	year = {2023},
	keywords = {hyperparameter-tuning, random-search-cv, grid-search-cv},
	file = {Snapshot:/home/ivan/Zotero/storage/FCFVM9ZU/hyperparameter-tuning-with-grid-search-and-random-search-6e1b5e175144.html:text/html},
}

@misc{boyle_hyperparameter_nodate,
	title = {Hyperparameter {Tuning}},
	url = {https://kaggle.com/code/tboyle10/hyperparameter-tuning},
	abstract = {Explore and run machine learning code with Kaggle Notebooks {\textbar} Using data from Don't Overfit! II},
	language = {en},
	urldate = {2024-01-20},
	author = {Boyle, Tara},
	keywords = {hyperparameter-tuning, sgd-classifier},
	file = {Snapshot:/home/ivan/Zotero/storage/GASBN7RP/hyperparameter-tuning.html:text/html},
}

@misc{tiwari_advanced_2023,
	title = {Advanced {Evaluation} {Metrics} for {Imbalanced} {Classification} {Models}},
	url = {https://medium.com/cuenex/advanced-evaluation-metrics-for-imbalanced-classification-models-ee6f248c90ca},
	abstract = {Measure Imbalanced Models the right way!},
	language = {en},
	urldate = {2024-01-25},
	journal = {CueNex},
	author = {Tiwari, Rajneesh},
	month = feb,
	year = {2023},
	keywords = {compare-classifiers, evaluation-metrics},
	file = {Snapshot:/home/ivan/Zotero/storage/W76ATLNU/advanced-evaluation-metrics-for-imbalanced-classification-models-ee6f248c90ca.html:text/html},
}

@misc{rutecki_best_nodate,
	title = {Best techniques and metrics for {Imbalanced} {Dataset}},
	url = {https://kaggle.com/code/marcinrutecki/best-techniques-and-metrics-for-imbalanced-dataset},
	abstract = {Explore and run machine learning code with Kaggle Notebooks {\textbar} Using data from multiple data sources},
	language = {en},
	urldate = {2024-01-25},
	author = {Rutecki, Marcin},
	keywords = {compare-classifiers, evaluation-metrics},
	file = {Snapshot:/home/ivan/Zotero/storage/V59GWJZZ/best-techniques-and-metrics-for-imbalanced-dataset.html:text/html},
}

@misc{rutecki_voting_nodate,
	title = {Voting {Classifier} for {Better} {Results}},
	url = {https://kaggle.com/code/marcinrutecki/voting-classifier-for-better-results},
	abstract = {Explore and run machine learning code with Kaggle Notebooks {\textbar} Using data from multiple data sources},
	language = {en},
	urldate = {2024-01-25},
	author = {Rutecki, Marcin},
	keywords = {voting-ensemble},
	file = {Snapshot:/home/ivan/Zotero/storage/7NZJ86PL/voting-classifier-for-better-results.html:text/html},
}

@misc{kawa_explainable_2022,
	title = {Explainable {AI} ({XAI}) with {Class} {Maps}},
	url = {https://towardsdatascience.com/explainable-ai-xai-with-class-maps-d0e137a91d2c},
	abstract = {Introducing a novel visual tool for explaining the results of classification algorithms, with examples in R and Python.},
	language = {en},
	urldate = {2024-01-29},
	journal = {Medium},
	author = {Kawa, Nura},
	month = feb,
	year = {2022},
	keywords = {explainable-ai},
	file = {Snapshot:/home/ivan/Zotero/storage/NP28NKTS/explainable-ai-xai-with-class-maps-d0e137a91d2c.html:text/html},
}

@article{dindorf_classification_2021,
	title = {Classification and {Automated} {Interpretation} of {Spinal} {Posture} {Data} {Using} a {Pathology}-{Independent} {Classifier} and {Explainable} {Artificial} {Intelligence} ({XAI})},
	volume = {21},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/21/18/6323},
	doi = {10.3390/s21186323},
	abstract = {Clinical classification models are mostly pathology-dependent and, thus, are only able to detect pathologies they have been trained for. Research is needed regarding pathology-independent classifiers and their interpretation. Hence, our aim is to develop a pathology-independent classifier that provides prediction probabilities and explanations of the classification decisions. Spinal posture data of healthy subjects and various pathologies (back pain, spinal fusion, osteoarthritis), as well as synthetic data, were used for modeling. A one-class support vector machine was used as a pathology-independent classifier. The outputs were transformed into a probability distribution according to Platt‚Äôs method. Interpretation was performed using the explainable artificial intelligence tool Local Interpretable Model-Agnostic Explanations. The results were compared with those obtained by commonly used binary classification approaches. The best classification results were obtained for subjects with a spinal fusion. Subjects with back pain were especially challenging to distinguish from the healthy reference group. The proposed method proved useful for the interpretation of the predictions. No clear inferiority of the proposed approach compared to commonly used binary classifiers was demonstrated. The application of dynamic spinal data seems important for future works. The proposed approach could be useful to provide an objective orientation and to individually adapt and monitor therapy measures pre- and post-operatively.},
	language = {en},
	number = {18},
	urldate = {2024-01-29},
	journal = {Sensors},
	author = {Dindorf, Carlo and Konradi, J√ºrgen and Wolf, Claudia and Taetz, Bertram and Bleser, Gabriele and Huthwelker, Janine and Werthmann, Friederike and Bartaguiz, Eva and Kniepert, Johanna and Drees, Philipp and Betz, Ulrich and Fr√∂hlich, Michael},
	month = jan,
	year = {2021},
	note = {Number: 18
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {explainable-ai, LIME},
	pages = {6323},
	file = {Full Text PDF:/home/ivan/Zotero/storage/IE9CWKM3/Dindorf et al. - 2021 - Classification and Automated Interpretation of Spi.pdf:application/pdf},
}

@article{massafra_analyzing_2023,
	title = {Analyzing breast cancer invasive disease event classification through explainable artificial intelligence},
	volume = {10},
	issn = {2296-858X},
	url = {https://www.frontiersin.org/articles/10.3389/fmed.2023.1116354},
	abstract = {IntroductionRecently, accurate machine learning and deep learning approaches have been dedicated to the investigation of breast cancer invasive disease events (IDEs), such as recurrence, contralateral and second cancers. However, such approaches are poorly interpretable.MethodsThus, we designed an Explainable Artificial Intelligence (XAI) framework to investigate IDEs within a cohort of 486 breast cancer patients enrolled at IRCCS Istituto Tumori ‚ÄúGiovanni Paolo II‚Äù in Bari, Italy. Using Shapley values, we determined the IDE driving features according to two periods, often adopted in clinical practice, of 5 and 10 years from the first tumor diagnosis.ResultsAge, tumor diameter, surgery type, and multiplicity are predominant within the 5-year frame, while therapy-related features, including hormone, chemotherapy schemes and lymphovascular invasion, dominate the 10-year IDE prediction. Estrogen Receptor (ER), proliferation marker Ki67 and metastatic lymph nodes affect both frames.DiscussionThus, our framework aims at shortening the distance between AI and clinical practice},
	urldate = {2024-01-29},
	journal = {Frontiers in Medicine},
	author = {Massafra, Raffaella and Fanizzi, Annarita and Amoroso, Nicola and Bove, Samantha and Comes, Maria Colomba and Pomarico, Domenico and Didonna, Vittorio and Diotaiuti, Sergio and Galati, Luisa and Giotta, Francesco and La Forgia, Daniele and Latorre, Agnese and Lombardi, Angela and Nardone, Annalisa and Pastena, Maria Irene and Ressa, Cosmo Maurizio and Rinaldi, Lucia and Tamborra, Pasquale and Zito, Alfredo and Paradiso, Angelo Virgilio and Bellotti, Roberto and Lorusso, Vito},
	year = {2023},
	keywords = {explainable-ai},
	file = {Full Text PDF:/home/ivan/Zotero/storage/RTG3FJBN/Massafra et al. - 2023 - Analyzing breast cancer invasive disease event cla.pdf:application/pdf},
}

@misc{cohen_explainable_2022,
	title = {Explainable {AI} ({XAI}) with {SHAP} -{Multi}-class classification problem},
	url = {https://towardsdatascience.com/explainable-ai-xai-with-shap-multi-class-classification-problem-64dd30f97cea},
	abstract = {Practical guide for XAI analysis with SHAP for a Multi-class classification problem},
	language = {en},
	urldate = {2024-02-01},
	journal = {Medium},
	author = {Cohen, Idit},
	month = may,
	year = {2022},
	keywords = {explainable-ai, SHAP},
	file = {Snapshot:/home/ivan/Zotero/storage/LCTVKUPP/explainable-ai-xai-with-shap-multi-class-classification-problem-64dd30f97cea.html:text/html},
}

@misc{gupta_classification_nodate,
	title = {Classification {Feature} {Selection} : {SHAP} {Tutorial}},
	shorttitle = {Classification {Feature} {Selection}},
	url = {https://kaggle.com/code/ritzig/classification-feature-selection-shap-tutorial},
	abstract = {Explore and run machine learning code with Kaggle Notebooks {\textbar} Using data from Mobile Price Classification},
	language = {en},
	urldate = {2024-02-01},
	author = {Gupta, Ritika},
	keywords = {explainable-ai, SHAP},
	file = {Snapshot:/home/ivan/Zotero/storage/8GTCHX25/notebook.html:text/html},
}

@article{gramegna_shap_2021,
	title = {{SHAP} and {LIME}: {An} {Evaluation} of {Discriminative} {Power} in {Credit} {Risk}},
	volume = {4},
	issn = {2624-8212},
	shorttitle = {{SHAP} and {LIME}},
	url = {https://www.frontiersin.org/articles/10.3389/frai.2021.752558},
	abstract = {In credit risk estimation, the most important element is obtaining a probability of default as close as possible to the effective risk. This effort quickly prompted new, powerful algorithms that reach a far higher accuracy, but at the cost of losing intelligibility, such as Gradient Boosting or ensemble methods. These models are usually referred to as ‚Äúblack-boxes‚Äù, implying that you know the inputs and the output, but there is little way to understand what is going on under the hood. As a response to that, we have seen several different Explainable AI models flourish in recent years, with the aim of letting the user see why the black-box gave a certain output. In this context, we evaluate two very popular eXplainable AI (XAI) models in their ability to discriminate observations into groups, through the application of both unsupervised and predictive modeling to the weights these XAI models assign to features locally. The evaluation is carried out on real Small and Medium Enterprises data, obtained from official italian repositories, and may form the basis for the employment of such XAI models for post-processing features extraction.},
	urldate = {2024-02-01},
	journal = {Frontiers in Artificial Intelligence},
	author = {Gramegna, Alex and Giudici, Paolo},
	year = {2021},
	keywords = {explainable-ai, LIME, SHAP},
	file = {Full Text PDF:/home/ivan/Zotero/storage/PHGRIG2E/Gramegna and Giudici - 2021 - SHAP and LIME An Evaluation of Discriminative Pow.pdf:application/pdf},
}

@misc{radecic_shap_2022,
	title = {{SHAP}: {How} to {Interpret} {Machine} {Learning} {Models} {With} {Python}},
	shorttitle = {{SHAP}},
	url = {https://towardsdatascience.com/shap-how-to-interpret-machine-learning-models-with-python-2323f5af4be9},
	abstract = {Explainable machine learning with a single function call},
	language = {en},
	urldate = {2024-02-01},
	journal = {Medium},
	author = {Radeƒçiƒá, Dario},
	month = mar,
	year = {2022},
	keywords = {explainable-ai, SHAP},
	file = {Snapshot:/home/ivan/Zotero/storage/EA4J7PK6/shap-how-to-interpret-machine-learning-models-with-python-2323f5af4be9.html:text/html},
}

@misc{radecic_lime_2022,
	title = {{LIME}: {How} to {Interpret} {Machine} {Learning} {Models} {With} {Python}},
	shorttitle = {{LIME}},
	url = {https://towardsdatascience.com/lime-how-to-interpret-machine-learning-models-with-python-94b0e7e4432e},
	abstract = {Explainable machine learning at your fingertips.},
	language = {en},
	urldate = {2024-02-01},
	journal = {Medium},
	author = {Radeƒçiƒá, Dario},
	month = mar,
	year = {2022},
	keywords = {explainable-ai, LIME},
	file = {Snapshot:/home/ivan/Zotero/storage/3MLHPB6K/lime-how-to-interpret-machine-learning-models-with-python-94b0e7e4432e.html:text/html},
}

@misc{radecic_lime_2022-1,
	title = {{LIME} vs. {SHAP}: {Which} is {Better} for {Explaining} {Machine} {Learning} {Models}?},
	shorttitle = {{LIME} vs. {SHAP}},
	url = {https://towardsdatascience.com/lime-vs-shap-which-is-better-for-explaining-machine-learning-models-d68d8290bb16},
	abstract = {Two of the most popular Explainers compared.},
	language = {en},
	urldate = {2024-02-01},
	journal = {Medium},
	author = {Radeƒçiƒá, Dario},
	month = mar,
	year = {2022},
	keywords = {explainable-ai, LIME, SHAP},
	file = {Snapshot:/home/ivan/Zotero/storage/AMSD6WBC/lime-vs-shap-which-is-better-for-explaining-machine-learning-models-d68d8290bb16.html:text/html},
}

@misc{luvsandorj_explaining_2021,
	title = {Explaining {Scikit}-learn models with {SHAP}},
	url = {https://towardsdatascience.com/explaining-scikit-learn-models-with-shap-61daff21b12a},
	abstract = {Towards explainable AI},
	language = {en},
	urldate = {2024-02-01},
	journal = {Medium},
	author = {Luvsandorj, Zolzaya},
	month = nov,
	year = {2021},
	keywords = {explainable-ai, SHAP},
	file = {Snapshot:/home/ivan/Zotero/storage/7SPHVCD5/explaining-scikit-learn-models-with-shap-61daff21b12a.html:text/html},
}

@article{de_lange_explainable_2022,
	title = {Explainable {AI} for {Credit} {Assessment} in {Banks}},
	volume = {15},
	doi = {10.3390/jrfm15120556},
	abstract = {Banks‚Äô credit scoring models are required by financial authorities to be explainable. This paper proposes an explainable artificial intelligence (XAI) model for predicting credit default on a unique dataset of unsecured consumer loans provided by a Norwegian bank. We combined a LightGBM model with SHAP, which enables the interpretation of explanatory variables affecting the predictions. The LightGBM model clearly outperforms the bank‚Äôs actual credit scoring model (Logistic Regression). We found that the most important explanatory variables for predicting default in the LightGBM model are the volatility of utilized credit balance, remaining credit in percentage of total credit and the duration of the customer relationship. Our main contribution is the implementation of XAI methods in banking, exploring how these methods can be applied to improve the interpretability and reliability of state-of-the-art AI models. We also suggest a method for analyzing the potential economic value of an improved credit scoring model.},
	journal = {Journal of Risk and Financial Management},
	author = {de Lange, Petter and Melsom, Borger and Venner√∏d, Christian and Westgaard, Sjur},
	month = nov,
	year = {2022},
	keywords = {explainable-ai, SHAP},
	pages = {556},
	file = {Full Text:/home/ivan/Zotero/storage/7XE2S6XQ/de Lange et al. - 2022 - Explainable AI for Credit Assessment in Banks.pdf:application/pdf},
}

@misc{spanhol_figure_nodate,
	title = {Figure 1. {A} slide of breast malignant tumor (stained with {HE}) seen in...},
	url = {https://www.researchgate.net/figure/A-slide-of-breast-malignant-tumor-stained-with-HE-seen-in-different-magnification_fig1_304158394},
	abstract = {Download scientific diagram {\textbar} A slide of breast malignant tumor (stained with HE) seen in different magnification factors: (a) 40√ó, (b) 100√ó, (c) 200√ó, and (d) 400√ó. Highlighted rectangle (manually added for illustrative purposes only) is the area of interest selected by pathologist to be detailed in the next higher magnification factor. ¬† from publication: Breast Cancer Histopathological Image Classification using Convolutional Neural Networks {\textbar} The performance of most conventional classification systems relies on appropriate data representation and much of the efforts are dedicated to feature engineering, a difficult and time-consuming process that uses prior expert domain knowledge of the data to create useful... {\textbar} Image Classification, Convolution and Breast Cancer {\textbar} ResearchGate, the professional network for scientists.},
	language = {en},
	urldate = {2024-02-19},
	journal = {ResearchGate},
	author = {Spanhol, Fabio},
	keywords = {image},
	file = {Snapshot:/home/ivan/Zotero/storage/P4Z9DNWT/A-slide-of-breast-malignant-tumor-stained-with-HE-seen-in-different-magnification_fig1_30415839.html:text/html},
}
