We know that \acl{lr} is the best classifier for our problem, but we want to know how it takes decisions and how sure it is of its decisions, especially when it fails. For this purpose, we used \ac{shap} to analyze the \ac{lr} classifier. We analyzed the global interpretability of the classifier and the local interpretability of some instances. The global analysis presents the importance of each feature in the model, and the local analysis shows the importance of each feature in a specific instance.