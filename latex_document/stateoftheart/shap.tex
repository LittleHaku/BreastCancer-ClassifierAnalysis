\newacronym{shap}{SHAP}{SHapley Additive exPlanations}
\newacronym{xai}{XAI}{Explainable Artificial Intelligence}

\ac{shap} \cite{lundberg_unified_2017} is a model-agnostic approach to \ac{xai}, that is, it can be used with any model since it only uses the input and output. In short, how \ac{shap} works, is that it uses the Shapley values from cooperative game theory to explain the output of any machine learning model. The Shapley value is a concept from cooperative game theory, it is a way to fairly distribute the loot obtained by a coalition of players. The difference is that in \ac{shap} instead of players we have features and instead of loot, we have the predicted output as a probability. The Shapley value is the average contribution of a feature to the prediction, and it is calculated by averaging the marginal contributions of a feature to the prediction over all possible orderings of the features. The marginal contribution of a feature to the prediction is the difference between the prediction with the feature and the prediction without the feature. This is done for all possible subsets of features, and then the Shapley value is the average of all these marginal contributions. This is done for all the features, and then we have the Shapley values, which are the importance of the features for the prediction.